# This workflow uses actions that are not certified by GitHub.
# They are provided by a third-party and are governed by
# separate terms of service, privacy policy, and support
# documentation.

# GitHub recommends pinning actions to a commit SHA.

# To get a newer version, you will need to update the SHA.
# You can also reference a tag or branch, but the action may change without warning.

name: Deploy Infrastructure

on:
  push:
    branches:
      - cicd_pipeline

jobs:
  deploy:
    name: Deploy Infrastructure
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v2

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@0e613a0980cbf65ed5b322eb7a1e075d28913a83
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}
      - name: Print AWS Profiles
        run: aws configure list-profiles
      - name: Setup Static Buckets
        shell: bash
        env:
          AWS_ACCOUNT_NUMBER: ${{ secrets.AWS_ACCOUNT_NUMBER }}
          OUTPUT_S3_BUCKET: ${{ secrets.OUTPUT_S3_BUCKET }}
          TFSTATE_S3_BUCKET: ${{ secrets.TFSTATE_S3_BUCKET }}
          AWS_REGION: ${{ secrets.AWS_REGION }}
          RUNNING_ON_GITHUB_ACTIONS: "true"
        run: |
          source sh/setup_static_buckets.sh "$AWS_ACCOUNT_NUMBER" "$OUTPUT_S3_BUCKET" "$TFSTATE_S3_BUCKET" "$AWS_REGION" "$RUNNING_ON_GITHUB_ACTIONS"

      - name: Create ECR Repo
        shell: bash
        env:
          AWS_ACCOUNT_NUMBER: ${{ secrets.AWS_ACCOUNT_NUMBER }}
          ECR_REPO_NAME: ${{ secrets.ECR_REPO_NAME }}
          AWS_REGION: ${{ secrets.AWS_REGION }}
          RUNNING_ON_GITHUB_ACTIONS: "true"
        run: |
          source sh/create_ecr_repo.sh "$AWS_ACCOUNT_NUMBER" "$ECR_REPO_NAME" "$AWS_REGION" "$RUNNING_ON_GITHUB_ACTIONS"

      - name: Package Lambdas
        shell: bash
        env:
          RUNNING_ON_GITHUB_ACTIONS: "true"
        run: |
          source sh/package_lambdas.sh ${GITHUB_WORKSPACE} "$RUNNING_ON_GITHUB_ACTIONS"

      - name: Export Environment Variables
        shell: bash
        env:
          RUNNING_ON_GITHUB_ACTIONS: "true"
        run: |
          source sh/export_env_vars.sh ${{ github.sha }} "$RUNNING_ON_GITHUB_ACTIONS"

      - name: Print Exported Environment Variables
        run: |
          echo "Exported Environment Variables:"
          printenv | grep TF_VAR

      - name: Print Environment Variables in $GITHUB_ENV
        run: |
          echo "Environment Variables in \$GITHUB_ENV:"
          cat $GITHUB_ENV

      - name: Terraform Init
        run: terraform init -backend-config="bucket=${{ secrets.TFSTATE_BUCKET }}" -backend-config="profile=${{ secrets.AWS_PROFILE }}" -backend-config="region=${{ secrets.AWS_REGION }}"

    #   - name: Terraform Plan
    #     id: plan
    #     env:
    #       aws_profile: ${{ secrets.TF_VAR_aws_profile }}
    #       aws_account_number: ${{ secrets.TF_VAR_aws_account_number }}
    #       aws_region: ${{ secrets.TF_VAR_aws_region }}
    #       airtable_secret_prefix: ${{ secrets.TF_VAR_airtable_secret_prefix }}
    #       airtable_base_id: ${{ secrets.TF_VAR_airtable_base_id }}
    #       airtable_table_id: ${{ secrets.TF_VAR_airtable_table_id }}
    #       airtable_api_token: ${{ secrets.TF_VAR_airtable_api_token }}
    #       mros_airtable_to_sqs_lambda_zip_file_name: ${{ secrets.TF_VAR_mros_airtable_to_sqs_lambda_zip_file_name }}
    #       mros_airtable_to_sqs_lambda_function_name: ${{ secrets.TF_VAR_mros_airtable_to_sqs_lambda_function_name }}
    #       mros_stage_to_prod_lambda_zip_file_name: ${{ secrets.TF_VAR_mros_stage_to_prod_lambda_zip_file_name }}
    #       mros_stage_to_prod_lambda_function_name: ${{ secrets.TF_VAR_mros_stage_to_prod_lambda_function_name }}
    #       sqs_consumer_lambda_function_name: ${{ secrets.TF_VAR_sqs_consumer_lambda_function_name }}
    #       mros_append_daily_data_lambda_zip_file_name: ${{ secrets.TF_VAR_mros_append_daily_data_lambda_zip_file_name }}
    #       mros_append_daily_data_lambda_function_name: ${{ secrets.TF_VAR_mros_append_daily_data_lambda_function_name }}
    #       insert_into_dynamodb_lambda_zip_file_name: ${{ secrets.TF_VAR_insert_into_dynamodb_lambda_zip_file_name }}
    #       insert_into_dynamodb_lambda_function_name: ${{ secrets.TF_VAR_insert_into_dynamodb_lambda_function_name }}
    #       dynamodb_table_name: ${{ secrets.TF_VAR_dynamodb_table_name }}
    #       sqs_queue_name: ${{ secrets.TF_VAR_sqs_queue_name }}
    #       sqs_stage_queue_name: ${{ secrets.TF_VAR_sqs_stage_queue_name }}
    #       sqs_prod_to_output_queue_name: ${{ secrets.TF_VAR_sqs_prod_to_output_queue_name }}
    #       lambda_bucket_name: ${{ secrets.TF_VAR_lambda_bucket_name }}
    #       airtable_s3_bucket_name: ${{ secrets.TF_VAR_airtable_s3_bucket_name }}
    #       staging_s3_bucket_name: ${{ secrets.TF_VAR_staging_s3_bucket_name }}
    #       prod_s3_bucket_name: ${{ secrets.TF_VAR_prod_s3_bucket_name }}
    #       nasa_data_user_env_var: ${{ secrets.TF_VAR_nasa_data_user_env_var }}
    #       nasa_data_password_env_var: ${{ secrets.TF_VAR_nasa_data_password_env_var }}
    #       mros_ecr_repo_name: ${{ secrets.TF_VAR_mros_ecr_repo_name }}
    #       mros_ecr_repo_url: ${{ secrets.TF_VAR_mros_ecr_repo_url }}
    #       sns_output_data_topic: ${{ secrets.TF_VAR_sns_output_data_topic }}
    #       eventbridge_cron_rule_name: ${{ secrets.TF_VAR_eventbridge_cron_rule_name }}
    #       output_s3_bucket_name: ${{ secrets.TF_VAR_output_s3_bucket_name }}
    #       output_s3_object_key: ${{ secrets.TF_VAR_output_s3_object_key }}
    #       tfstate_s3_bucket_name: ${{ secrets.TF_VAR_tfstate_s3_bucket_name }}
    #       tfstate_s3_object_key: ${{ secrets.TF_VAR_tfstate_s3_object_key }}
    #     run: |
    #       terraform plan \
    #         -var "aws_profile=${aws_profile}" \
    #         -var "aws_account_number=${aws_account_number}" \
    #         -var "aws_region=${aws_region}" \
    #         -var "airtable_secret_prefix=${airtable_secret_prefix}" \
    #         -var "airtable_base_id=${airtable_base_id}" \
    #         -var "airtable_table_id=${airtable_table_id}" \
    #         -var "airtable_api_token=${airtable_api_token}" \
    #         -var "mros_airtable_to_sqs_lambda_zip_file_name=${mros_airtable_to_sqs_lambda_zip_file_name}" \
    #         -var "mros_airtable_to_sqs_lambda_function_name=${mros_airtable_to_sqs_lambda_function_name}" \
    #         -var "mros_stage_to_prod_lambda_zip_file_name=${mros_stage_to_prod_lambda_zip_file_name}" \
    #         -var "mros_stage_to_prod_lambda_function_name=${mros_stage_to_prod_lambda_function_name}" \
    #         -var "sqs_consumer_lambda_function_name=${sqs_consumer_lambda_function_name}" \
    #         -var "mros_append_daily_data_lambda_zip_file_name=${mros_append_daily_data_lambda_zip_file_name}" \
    #         -var "mros_append_daily_data_lambda_function_name=${mros_append_daily_data_lambda_function_name}" \
    #         -var "insert_into_dynamodb_lambda_zip_file_name=${insert_into_dynamodb_lambda_zip_file_name}" \
    #         -var "insert_into_dynamodb_lambda_function_name=${insert_into_dynamodb_lambda_function_name}" \
    #         -var "dynamodb_table_name=${dynamodb_table_name}" \
    #         -var "sqs_queue_name=${sqs_queue_name}" \
    #         -var "sqs_stage_queue_name=${sqs_stage_queue_name}" \
    #         -var "sqs_prod_to_output_queue_name=${sqs_prod_to_output_queue_name}" \
    #         -var "lambda_bucket_name=${lambda_bucket_name}" \
    #         -var "airtable_s3_bucket_name=${airtable_s3_bucket_name}" \
    #         -var "staging_s3_bucket_name=${staging_s3_bucket_name}" \
    #         -var "prod_s3_bucket_name=${prod_s3_bucket_name}" \
    #         -var "nasa_data_user_env_var=${nasa_data_user_env_var}" \
    #         -var "nasa_data_password_env_var=${nasa_data_password_env_var}" \
    #         -var "mros_ecr_repo_name=${mros_ecr_repo_name}" \
    #         -var "mros_ecr_repo_url=${mros_ecr_repo_url}" \
    #         -var "sns_output_data_topic=${sns_output_data_topic}" \
    #         -var "eventbridge_cron_rule_name=${eventbridge_cron_rule_name}" \
    #         -var "output_s3_bucket_name=${output_s3_bucket_name}" \
    #         -var "output_s3_object_key=${output_s3_object_key}" \
    #         -var "tfstate_s3_bucket_name=${tfstate_s3_bucket_name}" \
    #         -var "tfstate_s3_object_key=${tfstate_s3_object_key}" \
    #     continue-on-error: true
    #   - name: Terraform Apply
    #     run: terraform apply -auto-approve
